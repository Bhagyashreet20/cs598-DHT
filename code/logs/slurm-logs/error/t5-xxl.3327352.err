
Currently Loaded Modules:
  1) cue-login-env/1.0   4) gcc/11.4.0      7) anaconda3_cpu/23.7.4
  2) slurm-env/0.1       5) openmpi/4.1.6
  3) default-s11         6) python/3.7.17

Inactive Modules:
  1) cuda

 

usage: conda [-h] [--no-plugins] [-V] COMMAND ...
conda: error: argument COMMAND: invalid choice: 'activate' (choose from 'clean', 'compare', 'config', 'create', 'info', 'init', 'install', 'list', 'notices', 'package', 'remove', 'uninstall', 'rename', 'run', 'search', 'update', 'upgrade', 'build', 'content-trust', 'convert', 'debug', 'develop', 'doctor', 'index', 'inspect', 'metapackage', 'render', 'skeleton', 'token', 'env', 'repo', 'verify', 'server')
You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. If you see this, DO NOT PANIC! This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=True`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565
Loading checkpoint shards:   0%|          | 0/5 [00:00<?, ?it/s]Loading checkpoint shards:  20%|██        | 1/5 [00:24<01:36, 24.24s/it]Loading checkpoint shards:  40%|████      | 2/5 [00:46<01:08, 22.85s/it]Loading checkpoint shards:  60%|██████    | 3/5 [01:26<01:01, 30.64s/it]Loading checkpoint shards:  80%|████████  | 4/5 [01:53<00:29, 29.27s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:06<00:00, 23.35s/it]Loading checkpoint shards: 100%|██████████| 5/5 [02:06<00:00, 25.21s/it]
Downloading generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]Downloading generation_config.json: 100%|██████████| 147/147 [00:00<00:00, 37.1kB/s]
/sw/external/python/anaconda3_cpu/lib/python3.9/site-packages/transformers/generation/utils.py:1254: UserWarning: Using the model-agnostic default `max_length` (=20) to control thegeneration length. We recommend setting `max_new_tokens` to control the maximum length of the generation.
  warnings.warn(
2024-03-29 12:08:11.439066: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2024-03-29 12:08:26.769544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
